
    // word count
    get_time( begin );
#if 0
    typedef asap::word_map<std::unordered_map<const char *, size_t, asap::text::charp_hash, asap::text::charp_eql>, asap::word_bank_pre_alloc> word_map_type;
#else
    typedef asap::word_map<std::map<const char *, size_t, asap::text::charp_cmp>, asap::word_bank_pre_alloc> word_map_type;
#endif
    typedef asap::kv_list<std::vector<std::pair<const char *, size_t>>, asap::word_bank_pre_alloc> word_list_type;

    typedef asap::sparse_vector<size_t, float, false,
				asap::mm_no_ownership_policy>
	vector_type;
#if 1
    typedef asap::word_map<std::unordered_map<const char *,
				    asap::appear_count<size_t,
						       typename vector_type::index_type>,
				    asap::text::charp_hash, asap::text::charp_eql>,
			   asap::word_bank_pre_alloc> word_map_type2;
#else
    typedef asap::word_map<std::map<const char *,
				    asap::appear_count<size_t,
						       typename vector_type::index_type>,
				    asap::text::charp_cmp>,
			   asap::word_bank_pre_alloc> word_map_type2;
#endif

    size_t num_files = dir_list.size();
    std::vector<word_list_type> catalog;
    catalog.resize( num_files );

    asap::word_container_reducer<word_map_type2> allwords;
    cilk_for( size_t i=0; i < num_files; ++i ) {
	std::string filename = *std::next(dir_list.cbegin(),i);
	// std::cerr << "Read file " << filename;
	{
	    // Build up catalog for each file using a map
	    word_map_type wmap;
	    asap::word_catalog<word_map_type>( filename, wmap );
	    // Convert file's catalog to a (sorted) list of pairs
	    catalog[i].reserve( wmap.size() );    // avoid re-allocations
	    catalog[i].insert( std::move(wmap) ); // move out wmap contents
	} // delete wmap

	// The list of pairs is sorted if word_map_type is based on std::map
	// but it is not sorted if based on std::unordered_map
	if( do_sort )
	    std::sort( catalog[i].begin(), catalog[i].end(),
		       asap::pair_cmp<word_map_type::value_type,
		       word_map_type::value_type>() );

	// std::cerr << ": " << catalog[i].size() << " words\n";
	// Reading from std::vector rather than std::map should be faster...
	// Validated: about 10% on word count, 20% on TF/IDF, 16 threads
	allwords.count_presence( catalog[i] );
    }
    get_time (end);
    print_time("word count", begin, end);

    get_time( begin );
    typedef asap::data_set<vector_type, word_map_type2, directory_listing_type> data_set_type;
    // TODO: consider linearising the word_map to a word_list with exchanged
    //       word_bank in order to avoid storing the ID? Problem: lookup
    //       during TF/IDF computation
    // TODO: infer word_map_type2 from word_map_type* in template definition?
    // TODO: construct aggregate word_map_type2 during wc loop above
    std::shared_ptr<word_map_type2> allwords_ptr
	= std::make_shared<word_map_type2>();
    allwords_ptr->swap( allwords.get_value() );

    std::shared_ptr<directory_listing_type> dir_list_ptr
	= std::make_shared<directory_listing_type>();
    dir_list_ptr->swap( dir_list );

    asap::internal::assign_ids( allwords_ptr->begin(), allwords_ptr->end() );

    data_set_type data_set
        = asap::tfidf<vector_type>(
            catalog.cbegin(), catalog.cend(), allwords_ptr, *allwords_ptr, dir_list_ptr , false, true);
    get_time( end );
    print_time("TF/IDF", begin, end);
    std::cerr << "TF/IDF number of words: " << data_set.get_dimensions()
	      << "\nTF/IDF number of files: " << data_set.get_num_points()
	      << std::endl;

    // Normalize data for improved clustering results
    get_time( begin );
    std::vector<std::pair<float, float>> extrema
	= asap::normalize( data_set );
    get_time( end );
    print_time("normalize", begin, end);

    // K-means clustering
    get_time( begin );
    auto kmeans_op = asap::kmeans( data_set, num_clusters, max_iters );
    get_time( end );
    print_time("K-Means", begin, end);
    std::cerr << "K-Means iterations: " << kmeans_op.num_iterations()
	      << "\nK-Means within-cluster SSE: " << kmeans_op.within_sse()
	      << std::endl;

    // Unscale data
    get_time( begin );
    asap::denormalize( extrema, data_set );
    get_time( end );        
    print_time("denormalize", begin, end);

